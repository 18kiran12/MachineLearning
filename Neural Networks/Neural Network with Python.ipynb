{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><center>Backprop Algorithm for Neural Network</center></h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of \n",
      "x : (4, 2) \n",
      "y : (4, 1)\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[1., 1.], [-1., 1.], [1., -1.], [-1., -1.]])\n",
    "y = np.array([1., 0., 0., 1.]).reshape(-1, 1)\n",
    "print(\"shape of \\nx : {} \\ny : {}\".format(x.shape, y.shape))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to work with a simple network that has one hidden layer (2 neurons). Since x has 2 features, we would need a weight matrix of 2X2 to map all the input features to the 2 neurons in the hidden layer as shown in the figure. The superscript shows the hidden layer number and the subscript of weights shows the mapping. The final prediction is classification and hence we need to calculate a single value from the 2 nodes. For this we use the 2 weights as shown in figure<br>\n",
    "<img src='img/NetStruct_NNPython.PNG'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the weight matrix for the first layer would be of the shape 2X2:\n",
    "\\begin{equation*}\n",
    "W = \\begin{vmatrix}\n",
    "w11 & w21\\\\\n",
    "w21 & w22\n",
    "\\end{vmatrix}\n",
    "\\end{equation*}\n",
    "Weights are arranged in such a way that each row produces output for a particular node i.e., w11 and w21 when multiplied with x1 and x2 correspondingly produces the input value of Node 1. Hence, the equation used for forward propogation is <b>np.dot(W, x)</b> where \n",
    "\\begin{equation*}\n",
    "X = \\begin{vmatrix}\n",
    "x1\\\\\n",
    "x2\n",
    "\\end{vmatrix}\n",
    "\\end{equation*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Initialize werights and bias</h4>\n",
    "<p>weights are initialized randomly and then learnt using backpropogation algorithm. Weights alone does not provide sufficient aggregate as this would predict 0 whenever x values are 0. Inorder for the function to predict a specific value even when all the inputs are 0 we need to add bias. Bias helps the aggregation to have a y - intercept which otherwise would have passed through the origin.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For layer 1, Random bias is \n",
      "[[1.76405235]\n",
      " [0.40015721]] \n",
      "Random weights is \n",
      "[[ 0.97873798  2.2408932 ]\n",
      " [ 1.86755799 -0.97727788]]\n",
      "For layer 1, Random bias is \n",
      "[[0.95008842]] \n",
      "Random weights is \n",
      "[[-0.15135721 -0.10321885]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(seed = 0)\n",
    "bias_layer1 = np.random.randn(2, 1)\n",
    "w1 = np.random.randn(2,2)\n",
    "bias_layer2 = np.random.randn(1, 1)\n",
    "w2 = np.random.randn(1,2)\n",
    "print(\"For layer 1, Random bias is \\n{} \\nRandom weights is \\n{}\".format(bias_layer1, w1))\n",
    "print(\"For layer 1, Random bias is \\n{} \\nRandom weights is \\n{}\".format(bias_layer2, w2))\n",
    "prev_w2 = w2\n",
    "prev_w1 = w1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Forward pass</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_prop(x, bias, W, is_lastlayer):\n",
    "    a = np.dot(W, x)\n",
    "    a = a.reshape(W.shape[0], 1)\n",
    "    a = a + bias\n",
    "    \"\"\"we are using a relu activation function\"\"\"\n",
    "    if(is_lastlayer):\n",
    "        h = a\n",
    "    else:\n",
    "        h = np.maximum(np.zeros((W.shape[0], 1)), a)\n",
    "    return a, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aggregate : [[4.98368353]\n",
      " [1.29043732]]\n",
      "relu activation : [[4.98368353]\n",
      " [1.29043732]]\n"
     ]
    }
   ],
   "source": [
    "a1, h1 = forward_prop(x[0], bias_layer1, w1, False)\n",
    "print(\"aggregate :\", a1)\n",
    "print(\"relu activation :\", h1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output we have from this calculation are values for Node1(h1) and Node2(h2) given in the figure. Now the neural network treats these values as inputs to find the final output using w2 and bias2. Since the output layer is a single node out weight matrix will have just a single row and bias would be a single number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aggregate : [[0.06257453]]\n",
      "relu activation : [[0.06257453]]\n"
     ]
    }
   ],
   "source": [
    "a2, h2 = forward_prop(h1, bias_layer2, w2, True)\n",
    "print(\"aggregate :\", a2)\n",
    "print(\"linear activation :\", h2)\n",
    "output = h2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, with the random weights that was selected the algorithm predicts 0 as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Backward pass</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we have to find the error in prediction and then propogate this error to modify all the weights so that the next prediction is a bit closer to the actual target value. Hence we start by claculating the deviation of the prediction to the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.87876651]]\n"
     ]
    }
   ],
   "source": [
    "sq_error = np.power((y[0] - output), 2)\n",
    "print(sq_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "derivative of the squared loss with respect to the output gives us the der_err as \n",
    "-2(y - output). The 2 constant can be ignored as this would be compensated by the learning rate. This is the error that gets propogated throughout the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.93742547]]\n"
     ]
    }
   ],
   "source": [
    "der_err = (output - y[0])\n",
    "print(der_err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inorder to calculate the component of this error that gets propogated to the weights we define a variable delta (delta_layer) as elementwise product of der_error and derivative of activation with aggregation (der_activation). der_activation in case of relu can be taken as 1 if activation is greater than 0 and 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "der_activation = 1 #no activation on last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.93742547]]\n"
     ]
    }
   ],
   "source": [
    "delta_layer2 = np.multiply(der_err, der_activation)\n",
    "print(delta_layer2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the derivative of error with respect to weights can be computed as dot product of delta_layer and previous activation output transposed (h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-4.67183186 -1.20968881]]\n"
     ]
    }
   ],
   "source": [
    "grad_weight2 = delta_layer2 * h1.T\n",
    "print(grad_weight2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have gradient computed from the error component. Using this and a learning rate we can calculate the updated w2 values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate : 0.01\n",
      "previous w : [[-0.15135721 -0.10321885]]\n"
     ]
    }
   ],
   "source": [
    "learn_rate = 0.01\n",
    "print(\"learning rate :\", learn_rate)\n",
    "prev_w2 = w2\n",
    "print(\"previous w :\", prev_w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated weights : [[-0.10463889 -0.09112196]]\n"
     ]
    }
   ],
   "source": [
    "w2 = w2 - learn_rate * grad_weight2\n",
    "print(\"Updated weights :\", w2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the updated w2 values for further back propogation and updating w1. This update is called dirty update and is widly accepted to be experimentaly better than actual update. Actual update would be the one that uses the old W values until the error with respect to those weights are fully propogated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Combining the back prop into a function</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_prop(prev_delta, is_last_layer, forward_weights, learn_rate, weights, bias\n",
    "              forward_activation, backward_activation):\n",
    "    \"\"\"derivative of activation \"\"\"\n",
    "    der_activation = forward_activation.copy()\n",
    "    der_activation[der_activation >= 0] = 1\n",
    "    der_activation[der_activation < 0] = 0\n",
    "    print(\"der_activation :\", der_activation)\n",
    "    \"\"\"error propogated through activation in front of the weights\"\"\"\n",
    "    activation_prop = delta_layer2 * der_activation\n",
    "    if(is_last_layer):\n",
    "        delta = prev_delta\n",
    "        grad_weight = delta * backward_activation.T\n",
    "    else:\n",
    "        delta = forward_weights.T * activation_prop\n",
    "        print(delta)\n",
    "        grad_weight = np.dot(delta, backward_activation.T)\n",
    "    print(\"grad :\", grad_weight)\n",
    "    print(\"prev weight : \", weights)\n",
    "    weights = weights - learn_rate * grad_weight\n",
    "#     bias = bias - learn_rate * delta\n",
    "    return delta, weights, bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "der_activation : [[1.]]\n",
      "grad : [[-4.67183186 -1.20968881]]\n",
      "prev weight :  [[-0.15135721 -0.10321885]]\n",
      "Delta in this layer :\n",
      " [[-0.93742547]]\n",
      "Updated weights :\n",
      " [[-0.10463889 -0.09112196]]\n"
     ]
    }
   ],
   "source": [
    "delta_layer2, w2_new, bias_layer2 = back_prop(der_err, True, None, 0.01, prev_w2, bias_layer2, h2, h1)\n",
    "print(\"Delta in this layer :\\n\", delta_layer2)\n",
    "print(\"Updated weights :\\n\", w2_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "der_activation : [[1.]\n",
      " [1.]]\n",
      "[[0.09809116]\n",
      " [0.08542005]]\n",
      "grad : [[0.09809116 0.09809116]\n",
      " [0.08542005 0.08542005]]\n",
      "prev weight :  [[ 0.97873798  2.2408932 ]\n",
      " [ 1.86755799 -0.97727788]]\n",
      "Delta in this layer :\n",
      " [[0.09809116]\n",
      " [0.08542005]]\n",
      "Updated weights :\n",
      " [[ 0.97775707  2.23991229]\n",
      " [ 1.86670379 -0.97813208]]\n"
     ]
    }
   ],
   "source": [
    "delta_layer1, w1_new, bias_layer2 = back_prop(delta_layer2, False, w2_new, 0.01, prev_w1, bias_layer1, h1, x[0].reshape(-1, 1))\n",
    "print(\"Delta in this layer :\\n\", delta_layer1)\n",
    "print(\"Updated weights :\\n\", w1_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Error Computaion</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error(output, target):\n",
    "    sq_loss = np.sum(np.power((target - output), 2))\n",
    "    return sq_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Complete program</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_prop(x, bias, W, is_lastlayer):\n",
    "    a = np.dot(W, x)\n",
    "    a = a.reshape(W.shape[0], 1)\n",
    "    a = a + bias\n",
    "    if(is_lastlayer):\n",
    "        h = a\n",
    "    else:\n",
    "        \"\"\"using a relu activation function\"\"\"\n",
    "        h = np.maximum(np.zeros((W.shape[0], 1)), a)\n",
    "    return a, h\n",
    "\n",
    "def error(output, target):\n",
    "    marginalize = len(target)\n",
    "    sq_loss = np.sum(np.power((target - output), 2))\n",
    "    rmse_loss = np.sqrt(sq_loss/marginalize)\n",
    "    return rmse_loss\n",
    "\n",
    "def back_prop(prev_delta, is_last_layer, forward_weights, learn_rate, \n",
    "              weights, bias, forward_activation, backward_activation, reg_const):\n",
    "    \"\"\"derivative of activation \"\"\"\n",
    "    der_activation = forward_activation.copy()\n",
    "    der_activation[der_activation >= 0] = 1\n",
    "    der_activation[der_activation < 0] = 0\n",
    "    \"\"\"error propogated through activation in front of the weights\"\"\"\n",
    "    activation_prop = prev_delta * der_activation\n",
    "    if(is_last_layer):\n",
    "        delta = prev_delta\n",
    "        grad_weight = delta * backward_activation.T\n",
    "    else:\n",
    "        delta = forward_weights.T * activation_prop\n",
    "        grad_weight = np.dot(delta, backward_activation.T)\n",
    "    weights = weights - learn_rate * (grad_weight + reg_const * weights)\n",
    "    bias = bias - learn_rate * delta\n",
    "    return delta, weights, bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"intializing parameters\"\"\"\n",
    "verbose = 0\n",
    "epochs = 500\n",
    "learn_rate = 0.01\n",
    "reg_const = 0.1\n",
    "\n",
    "\"\"\"initializing x and y\"\"\"\n",
    "x = np.array([[1., 1.], [-1., 1.], [1., -1.], [-1., -1.]])\n",
    "y = np.array([1., 0., 0., 1.]).reshape(-1, 1)\n",
    "if(verbose ==1):\n",
    "    print(\"Target values :\", y.tolist())\n",
    "\n",
    "\"\"\"initializing weights and bias\"\"\"\n",
    "\n",
    "np.random.seed(seed = 0)\n",
    "bias_layer1 = np.random.randn(2, 1)\n",
    "w1 = np.random.randn(2,2)\n",
    "bias_layer2 = np.random.randn(1, 1)\n",
    "w2 = np.random.randn(1,2)\n",
    "n = len(x)\n",
    "loss_list = []\n",
    "x_order = np.arange(n)\n",
    "\n",
    "\"\"\"iterating through number of epochs\"\"\"\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    \"\"\"iterating through each row stochastic\"\"\"\n",
    "    prediction_list = []\n",
    "#     shuffle(x_order)\n",
    "    for i in x_order:\n",
    "\n",
    "        \"\"\"forward pass\"\"\"\n",
    "        a1, h1 = forward_prop(x[i], bias_layer1, w1, False)\n",
    "        a2, h2 = forward_prop(h1, bias_layer2, w2, True)\n",
    "        output = h2\n",
    "        prediction_list.append(output)\n",
    "\n",
    "        \"\"\"error component\"\"\"\n",
    "        der_err = (output - y[i])\n",
    "\n",
    "        \"\"\"backward propogation\"\"\"\n",
    "        delta_layer2, w2, bias_layer2 = back_prop(der_err, True, None, learn_rate, w2, bias_layer2, h2, h1, reg_const)\n",
    "        delta_layer1, w1, bias_layer1 = back_prop(delta_layer2, False, w2, learn_rate, w1, bias_layer1, h1,\n",
    "                                     x[i].reshape(-1, 1), reg_const)\n",
    "\n",
    "    \"\"\"check prediction after an epoch\"\"\"\n",
    "    prediction = np.array(prediction_list).reshape(-1, 1)\n",
    "    loss = error(y, prediction)\n",
    "    if(verbose == 1):\n",
    "        print(\"After epoch : \", epoch)\n",
    "        print(\"\\tPrediction : \", prediction_list)\n",
    "        print(\"\\tLoss is : {}\\n\\n\".format(epoch, loss))\n",
    "    loss_list.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b4aa2d6550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(14,7))\n",
    "plt.plot(range(epochs), loss_list, label = \"Training loss\")\n",
    "plt.xlabel('# of epochs')\n",
    "plt.ylabel('RMSE Loss')\n",
    "plt.title(\"RMSE variation with increasing epochs\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
