{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Understanding Convolutional 1D and 2D diff</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"importing the required modules\"\"\"\n",
    "import numpy as np\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Even after going through some of the papers and documentation was not able to understand the clear difference between conv 1D , 2D and 3D network. That is when I came across this answer in stackexchange and tried to implement the same\n",
    "<a href = \"https://stackoverflow.com/questions/42883547/what-do-you-mean-by-1d-2d-and-3d-convolutions-in-cnn\"> here. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Conv 1D</h3>\n",
    "<p>A vector is used as the filter for convolution layer. For example, consider the case of graph smoothening. We multiply each value in the input with its resepective weights inorder to get a smoothened graph. Might not be able to get the 2d structure of objects in the image and hence less observed.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'Reshape:0' shape=(1, 5, 1) dtype=float32>,\n",
       " <tf.Tensor 'Reshape_1:0' shape=(3, 1, 1) dtype=float32>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_1d   = tf.reshape(in_1d, [1, in_width, 1])\n",
    "kernel_1d = tf.reshape(filter_1d, [filter_width, 1, 1])\n",
    "output_1d = tf.squeeze(tf.nn.conv1d(input_1d, kernel_1d, strides_1d, padding='SAME'))\n",
    "input_1d, kernel_1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, Dimension(5))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_width = int(in_1d.shape[0])\n",
    "filter_width = int(filter_1d.shape[0])\n",
    "in_width, in_1d.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 3. 3. 3. 2.]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"start a session in tf\"\"\"\n",
    "sess = tf.Session()\n",
    "\n",
    "\"\"\"define the parameters\"\"\"\n",
    "ones_1d = np.ones(5) #array([1., 1., 1., 1., 1.])\n",
    "weight_1d = np.ones(3) #array([1., 1., 1.])\n",
    "strides_1d = 1\n",
    "\n",
    "\"\"\"set them as tf constants\"\"\"\n",
    "in_1d = tf.constant(ones_1d, dtype=tf.float32)\n",
    "filter_1d = tf.constant(weight_1d, dtype=tf.float32)\n",
    "\n",
    "\"\"\"reshping the array as [1, 5, 1]\"\"\"\n",
    "input_1d   = tf.reshape(in_1d, [1, int(in_1d.shape[0]), 1]) #<tf.Tensor 'Reshape:0' shape=(1, 5, 1) dtype=float32>\n",
    "kernel_1d = tf.reshape(filter_1d, [int(filter_1d.shape[0]), 1, 1])\n",
    "\n",
    "output_1d = tf.squeeze(tf.nn.conv1d(input_1d, kernel_1d, strides_1d, padding='SAME'))\n",
    "print (sess.run(output_1d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>TF documentation - Computes a 1-D convolution given 3-D input and filter tensors.\n",
    "\n",
    "Given an input tensor of shape [batch, in_width, in_channels] if data_format is \"NHWC\", or [batch, in_channels, in_width] if data_format is \"NCHW\", and a filter / kernel tensor of shape [filter_width, in_channels, out_channels], this op reshapes the arguments to pass them to conv2d to perform the equivalent convolution operation. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Conv 2D</h3>\n",
    "<p>2-direction (x,y) to calculate convolution. A 2D filter is used and this 2D filter learns the same weights that help the kernel to learn a particular feature from the image.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4. 6. 6. 6. 4.]\n",
      " [6. 9. 9. 9. 6.]\n",
      " [6. 9. 9. 9. 6.]\n",
      " [6. 9. 9. 9. 6.]\n",
      " [4. 6. 6. 6. 4.]]\n"
     ]
    }
   ],
   "source": [
    "ones_2d = np.ones((5,5))\n",
    "weight_2d = np.ones((3,3))\n",
    "strides_2d = [1, 1, 1, 1]\n",
    "\n",
    "in_2d = tf.constant(ones_2d, dtype=tf.float32)\n",
    "filter_2d = tf.constant(weight_2d, dtype=tf.float32)\n",
    "\n",
    "in_width = int(in_2d.shape[0])\n",
    "in_height = int(in_2d.shape[1])\n",
    "\n",
    "filter_width = int(filter_2d.shape[0])\n",
    "filter_height = int(filter_2d.shape[1])\n",
    "\n",
    "input_2d   = tf.reshape(in_2d, [1, in_height, in_width, 1])\n",
    "kernel_2d = tf.reshape(filter_2d, [filter_height, filter_width, 1, 1])\n",
    "\n",
    "output_2d = tf.squeeze(tf.nn.conv2d(input_2d, kernel_2d, strides=strides_2d, padding='SAME'))\n",
    "print (sess.run(output_2d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Conv 3D</h3>\n",
    "<p>We can think of this as creating a small cube from a large one. Here the output and input is 3D</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 8. 12. 12. 12.  8.]\n",
      "  [12. 18. 18. 18. 12.]\n",
      "  [12. 18. 18. 18. 12.]\n",
      "  [12. 18. 18. 18. 12.]\n",
      "  [ 8. 12. 12. 12.  8.]]\n",
      "\n",
      " [[12. 18. 18. 18. 12.]\n",
      "  [18. 27. 27. 27. 18.]\n",
      "  [18. 27. 27. 27. 18.]\n",
      "  [18. 27. 27. 27. 18.]\n",
      "  [12. 18. 18. 18. 12.]]\n",
      "\n",
      " [[12. 18. 18. 18. 12.]\n",
      "  [18. 27. 27. 27. 18.]\n",
      "  [18. 27. 27. 27. 18.]\n",
      "  [18. 27. 27. 27. 18.]\n",
      "  [12. 18. 18. 18. 12.]]\n",
      "\n",
      " [[12. 18. 18. 18. 12.]\n",
      "  [18. 27. 27. 27. 18.]\n",
      "  [18. 27. 27. 27. 18.]\n",
      "  [18. 27. 27. 27. 18.]\n",
      "  [12. 18. 18. 18. 12.]]\n",
      "\n",
      " [[ 8. 12. 12. 12.  8.]\n",
      "  [12. 18. 18. 18. 12.]\n",
      "  [12. 18. 18. 18. 12.]\n",
      "  [12. 18. 18. 18. 12.]\n",
      "  [ 8. 12. 12. 12.  8.]]]\n"
     ]
    }
   ],
   "source": [
    "ones_3d = np.ones((5,5,5))\n",
    "weight_3d = np.ones((3,3,3))\n",
    "strides_3d = [1, 1, 1, 1, 1]\n",
    "\n",
    "in_3d = tf.constant(ones_3d, dtype=tf.float32)\n",
    "filter_3d = tf.constant(weight_3d, dtype=tf.float32)\n",
    "\n",
    "in_width = int(in_3d.shape[0])\n",
    "in_height = int(in_3d.shape[1])\n",
    "in_depth = int(in_3d.shape[2])\n",
    "\n",
    "filter_width = int(filter_3d.shape[0])\n",
    "filter_height = int(filter_3d.shape[1])\n",
    "filter_depth = int(filter_3d.shape[2])\n",
    "\n",
    "input_3d   = tf.reshape(in_3d, [1, in_depth, in_height, in_depth, 1])\n",
    "kernel_3d = tf.reshape(filter_3d, [filter_depth, filter_height, filter_width, 1, 1])\n",
    "\n",
    "output_3d = tf.squeeze(tf.nn.conv3d(input_3d, kernel_3d, strides=strides_3d, padding='SAME'))\n",
    "print (sess.run(output_3d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The concepts are defined in the paper titled \"Learning Spatiotemporal Features with 3D Convolutional Networks\"</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
